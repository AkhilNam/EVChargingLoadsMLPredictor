{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkhilNam/EVChargingLoadsMLPredictor/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukOYsVF6PsCt"
      },
      "source": [
        "# Predicting Residential EV Charging Loads using Neural Networks\n",
        "\n",
        "- [View Solution Notebook](./solutions.html)\n",
        "- [View Project Page](https://www.codecademy.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qT-KM6l7PsCu"
      },
      "outputs": [],
      "source": [
        "# Setup - import basic data libraries\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3dEDBdWPsCv"
      },
      "source": [
        "## Task Group 1 - Load, Inspect, and Merge Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG4I0z8IPsCv"
      },
      "source": [
        "### Task 1\n",
        "\n",
        "The file `'datasets/EV charging reports.csv'` contains electric vehicle (EV) charging data. These come from various residential apartment buildings in Norway. The data includes specific user and garage information, plug-in and plug-out times, charging loads, and the dates of the charging sessions.\n",
        "\n",
        "Import this CSV file to a pandas DataFrame named `ev_charging_reports`.\n",
        "\n",
        "Use the `.head()` method to preview the first five rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwofTKrUPsCv",
        "outputId": "03adb855-4f35-4d83-c1eb-8d81d049c35e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>session_ID;Garage_ID;User_ID;User_type;Shared_ID;Start_plugin;Start_plugin_hour;End_plugout;End_plugout_hour;El_kWh;Duration_hours;month_plugin;weekdays_plugin;Plugin_category;Duration_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1;AdO3;AdO3-4;Private;NA;21.12.2018 10:20;10;21.12.2018 10:23;10;0</th>\n",
              "      <th>3;0</th>\n",
              "      <td>05;Dec;Friday;late morning (9-12);Less than 3 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2;AdO3;AdO3-4;Private;NA;21.12.2018 10:24;10;21.12.2018 10:32;10;0</th>\n",
              "      <th>87;0</th>\n",
              "      <td>136666667;Dec;Friday;late morning (9-12);Less ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3;AdO3;AdO3-4;Private;NA;21.12.2018 11:33;11;21.12.2018 19:46;19;29</th>\n",
              "      <th>87;8</th>\n",
              "      <td>216388889;Dec;Friday;late morning (9-12);Betwe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4;AdO3;AdO3-2;Private;NA;22.12.2018 16:15;16;23.12.2018 16:40;16;15</th>\n",
              "      <th>56;24</th>\n",
              "      <td>41972222;Dec;Saturday;late afternoon (15-18);M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5;AdO3;AdO3-2;Private;NA;24.12.2018 22:03;22;24.12.2018 23:02;23;3</th>\n",
              "      <th>62;0</th>\n",
              "      <td>970555556;Dec;Monday;late evening (21-midnight...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                         session_ID;Garage_ID;User_ID;User_type;Shared_ID;Start_plugin;Start_plugin_hour;End_plugout;End_plugout_hour;El_kWh;Duration_hours;month_plugin;weekdays_plugin;Plugin_category;Duration_category\n",
              "1;AdO3;AdO3-4;Private;NA;21.12.2018 10:20;10;21... 3;0    05;Dec;Friday;late morning (9-12);Less than 3 ...                                                                                                                                               \n",
              "2;AdO3;AdO3-4;Private;NA;21.12.2018 10:24;10;21... 87;0   136666667;Dec;Friday;late morning (9-12);Less ...                                                                                                                                               \n",
              "3;AdO3;AdO3-4;Private;NA;21.12.2018 11:33;11;21... 87;8   216388889;Dec;Friday;late morning (9-12);Betwe...                                                                                                                                               \n",
              "4;AdO3;AdO3-2;Private;NA;22.12.2018 16:15;16;23... 56;24  41972222;Dec;Saturday;late afternoon (15-18);M...                                                                                                                                               \n",
              "5;AdO3;AdO3-2;Private;NA;24.12.2018 22:03;22;24... 62;0   970555556;Dec;Monday;late evening (21-midnight...                                                                                                                                               "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ev_charging_reports = pd.read_csv('datasets/EV charging reports.csv')\n",
        "ev_charging_reports.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I6cyrl6PsCv"
      },
      "source": [
        "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">What is the structure of the dataset?</summary>\n",
        "\n",
        "- **session_ID** - the unique id for each EV charging session\n",
        "- **Garage_ID** - the unique id for the garage of the apartment\n",
        "- **User_ID** - the unique id for each user\n",
        "- **User_private** - 1.0 indicates private charge point spaces and 0.0 indicates shared charge point spaces\n",
        "- **Shared_ID** - the unique id if shared charge point spaces are used\n",
        "- **Start_plugin** - the plug-in date and time in the format (day.month.year hour:minute)\n",
        "- **Start_plugin_hour** - the plug-in date and time rounded to the start of the hour\n",
        "- **End_plugout** - the plug-out date and time in the format (day.month.year hour:minute)\n",
        "- **End_plugout_hour** - the start of the hour of the `End_plugout` hour\n",
        "- **El_kWh** - the charged energy in kWh (charging loads)\n",
        "- **Duration_hours** - the duration of the EV connection time per session\n",
        "- **Plugin_category** - the plug-in time categorized by early/late night, morning, afternoon, and evening\n",
        "- **Duration_category** - the plug-in duration categorized by 3 hour groups\n",
        "- **month_plugin_{month}** - the month of the plug-in session\n",
        "- **weekdays_plugin_{day}** - the day of the week of the plug-in session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7ZccBfrPsCv"
      },
      "source": [
        "### Task 2\n",
        "\n",
        "Import the file `'datasets/Local traffic distribution.csv'` to a pandas DataFrame named `traffic_reports`. This dataset contains the hourly local traffic density counts at 5 nearby traffic locations.\n",
        "\n",
        "Preview the first five rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97OvL2jjPsCw",
        "outputId": "c8e88d86-5678-4483-b4a0-dfe5449865f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date_from;Date_to;KROPPAN BRU;MOHOLTLIA;SELSBAKK;MOHOLT RAMPE 2;Jonsvannsveien vest for Steinanvegen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01.12.2018 00:00;01.12.2018 01:00;639;0;0;4;144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01.12.2018 01:00;01.12.2018 02:00;487;153;115;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01.12.2018 02:00;01.12.2018 03:00;408;85;75;10;69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01.12.2018 03:00;01.12.2018 04:00;282;89;56;8;39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01.12.2018 04:00;01.12.2018 05:00;165;64;34;3;25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Date_from;Date_to;KROPPAN BRU;MOHOLTLIA;SELSBAKK;MOHOLT RAMPE 2;Jonsvannsveien vest for Steinanvegen\n",
              "0    01.12.2018 00:00;01.12.2018 01:00;639;0;0;4;144                                                  \n",
              "1  01.12.2018 01:00;01.12.2018 02:00;487;153;115;...                                                  \n",
              "2  01.12.2018 02:00;01.12.2018 03:00;408;85;75;10;69                                                  \n",
              "3   01.12.2018 03:00;01.12.2018 04:00;282;89;56;8;39                                                  \n",
              "4   01.12.2018 04:00;01.12.2018 05:00;165;64;34;3;25                                                  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "traffic_reports = pd.read_csv('datasets/Local traffic distribution.csv')\n",
        "traffic_reports.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zgAPnq3PsCw"
      },
      "source": [
        "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">What is the structure of the dataset?</summary>\n",
        "\n",
        "- **Date_from** - the starting time in the format (day.month.year hour:minute)\n",
        "- **Date_to** - the ending time in the format (day.month.year hour:minute)\n",
        "- **Location 1 to 5** - contains the number of vehicles each hour at a specified traffic location.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_pZYCkYPsCw"
      },
      "source": [
        "### Task 3\n",
        "\n",
        "We'd like to use the traffic data to help our model. The same charging location may charge at different rates depending on the number of cars being charged, so this traffic data might help the model out.\n",
        "\n",
        "Merge the `ev_charging_reports` and `traffic_reports` datasets together into a Dataframe named `ev_charging_traffic` using the columns:\n",
        "\n",
        "- `Start_plugin_hour` in `ev_charging_reports`\n",
        "- `Date_from` in `traffic_reports`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVhwLdhqPsCw",
        "outputId": "d0f6bafe-5a3b-4c5c-d1ae-12159d7afae2"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'Date_from'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1420\\3293935486.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m ev_charging_traffic = pd.merge(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mev_charging_reports\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtraffic_reports\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Start_plugin_hour'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         )\n\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         op = _MergeOperation(\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1293\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1298\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1911\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'Date_from'"
          ]
        }
      ],
      "source": [
        "ev_charging_traffic = pd.merge(\n",
        "    ev_charging_reports,\n",
        "    traffic_reports,\n",
        "    left_on='Start_plugin_hour',\n",
        "    right_on='Date_from',\n",
        "    how='left'\n",
        ")\n",
        "ev_charging_traffic.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5EQaXNGPsCw"
      },
      "source": [
        "### Task 4\n",
        "\n",
        "Use `.info()` to inspect the merged dataset. Specifically, pay attention to the data types and number of missing values in each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkj3XHVFPsCw",
        "outputId": "3e65ee43-7f01-46fc-b9ae-9541794cf01e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ev_charging_traffic' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mev_charging_traffic\u001b[49m\u001b[38;5;241m.\u001b[39minfo()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'ev_charging_traffic' is not defined"
          ]
        }
      ],
      "source": [
        "ev_charging_traffic.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRzTNJrpPsCw"
      },
      "source": [
        "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">What do we notice about merged dataset under inspection?</summary>\n",
        "\n",
        "We see that there are 39 columns and 6,833 rows in our merged dataset.\n",
        "\n",
        "Some notable things we might have to address:\n",
        "\n",
        "- We expected columns like `El_kWh` and `Duration_hours` to be floats but they are actually object data types.\n",
        "\n",
        "- There are many identifying columns like `session_ID` and `User_ID` that might not be useful for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TnudmJ4PsCw"
      },
      "source": [
        "## Task Group 2 - Data Cleaning and Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u6mNGRPPsCw"
      },
      "source": [
        "### Task 5\n",
        "\n",
        "Let's start by reducing the size of our dataset by dropping columns that won't be used for training. These include\n",
        "- ID columns\n",
        "- columns with lots of missing data\n",
        "- non-numeric columns (for now, since we haven't yet covered using non-numeric data in neural networks)\n",
        "\n",
        "Drop columns you don't want to use in training from `ev_charging_traffic_hourly`.\n",
        "\n",
        "To match our solution, drop the columns\n",
        "\n",
        "```py\n",
        "['session_ID', 'Garage_ID', 'User_ID',\n",
        "                'Shared_ID',\n",
        "                'Plugin_category','Duration_category',\n",
        "                'Start_plugin', 'Start_plugin_hour', 'End_plugout', 'End_plugout_hour',\n",
        "                'Date_from', 'Date_to']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIhMDZ0JPsCw",
        "outputId": "f07a7e72-1b9b-433c-a0b4-6531d43bef70"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_private</th>\n",
              "      <th>El_kWh</th>\n",
              "      <th>Duration_hours</th>\n",
              "      <th>month_plugin_Apr</th>\n",
              "      <th>month_plugin_Aug</th>\n",
              "      <th>month_plugin_Dec</th>\n",
              "      <th>month_plugin_Feb</th>\n",
              "      <th>month_plugin_Jan</th>\n",
              "      <th>month_plugin_Jul</th>\n",
              "      <th>month_plugin_Jun</th>\n",
              "      <th>...</th>\n",
              "      <th>weekdays_plugin_Saturday</th>\n",
              "      <th>weekdays_plugin_Sunday</th>\n",
              "      <th>weekdays_plugin_Thursday</th>\n",
              "      <th>weekdays_plugin_Tuesday</th>\n",
              "      <th>weekdays_plugin_Wednesday</th>\n",
              "      <th>Kroppan_bru_traffic</th>\n",
              "      <th>Moholtlia_traffic</th>\n",
              "      <th>Selsbakk_traffic</th>\n",
              "      <th>Moholt_rampe_2_traffic</th>\n",
              "      <th>Jonsvannsveien_vest_steinanvegen_traffic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0,3</td>\n",
              "      <td>0,05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3244.0</td>\n",
              "      <td>1632.0</td>\n",
              "      <td>545.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>622.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0,87</td>\n",
              "      <td>0,136666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3244.0</td>\n",
              "      <td>1632.0</td>\n",
              "      <td>545.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>622.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>29,87</td>\n",
              "      <td>8,216388889</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3605.0</td>\n",
              "      <td>1691.0</td>\n",
              "      <td>605.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>771.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>15,56</td>\n",
              "      <td>24,41972222</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3052.0</td>\n",
              "      <td>1484.0</td>\n",
              "      <td>453.0</td>\n",
              "      <td>224.0</td>\n",
              "      <td>694.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3,62</td>\n",
              "      <td>0,970555556</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1390.0</td>\n",
              "      <td>693.0</td>\n",
              "      <td>226.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>353.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   User_private El_kWh Duration_hours  month_plugin_Apr  month_plugin_Aug  \\\n",
              "0           1.0    0,3           0,05               0.0               0.0   \n",
              "1           1.0   0,87    0,136666667               0.0               0.0   \n",
              "2           1.0  29,87    8,216388889               0.0               0.0   \n",
              "3           1.0  15,56    24,41972222               0.0               0.0   \n",
              "4           1.0   3,62    0,970555556               0.0               0.0   \n",
              "\n",
              "   month_plugin_Dec  month_plugin_Feb  month_plugin_Jan  month_plugin_Jul  \\\n",
              "0               1.0               0.0               0.0               0.0   \n",
              "1               1.0               0.0               0.0               0.0   \n",
              "2               1.0               0.0               0.0               0.0   \n",
              "3               1.0               0.0               0.0               0.0   \n",
              "4               1.0               0.0               0.0               0.0   \n",
              "\n",
              "   month_plugin_Jun  ...  weekdays_plugin_Saturday  weekdays_plugin_Sunday  \\\n",
              "0               0.0  ...                       0.0                     0.0   \n",
              "1               0.0  ...                       0.0                     0.0   \n",
              "2               0.0  ...                       0.0                     0.0   \n",
              "3               0.0  ...                       1.0                     0.0   \n",
              "4               0.0  ...                       0.0                     0.0   \n",
              "\n",
              "   weekdays_plugin_Thursday  weekdays_plugin_Tuesday  \\\n",
              "0                       0.0                      0.0   \n",
              "1                       0.0                      0.0   \n",
              "2                       0.0                      0.0   \n",
              "3                       0.0                      0.0   \n",
              "4                       0.0                      0.0   \n",
              "\n",
              "   weekdays_plugin_Wednesday  Kroppan_bru_traffic  Moholtlia_traffic  \\\n",
              "0                        0.0               3244.0             1632.0   \n",
              "1                        0.0               3244.0             1632.0   \n",
              "2                        0.0               3605.0             1691.0   \n",
              "3                        0.0               3052.0             1484.0   \n",
              "4                        0.0               1390.0              693.0   \n",
              "\n",
              "   Selsbakk_traffic  Moholt_rampe_2_traffic  \\\n",
              "0             545.0                   194.0   \n",
              "1             545.0                   194.0   \n",
              "2             605.0                   230.0   \n",
              "3             453.0                   224.0   \n",
              "4             226.0                    83.0   \n",
              "\n",
              "   Jonsvannsveien_vest_steinanvegen_traffic  \n",
              "0                                     622.0  \n",
              "1                                     622.0  \n",
              "2                                     771.0  \n",
              "3                                     694.0  \n",
              "4                                     353.0  \n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "columns_to_drop = [\n",
        "    'session_ID', 'Garage_ID', 'User_ID',\n",
        "    'Shared_ID', 'Plugin_category', 'Duration_category',\n",
        "    'Start_plugin', 'Start_plugin_hour', 'End_plugout', 'End_plugout_hour',\n",
        "    'Date_from', 'Date_to'\n",
        "]\n",
        "\n",
        "# Drop columns from ev_charging_traffic\n",
        "ev_charging_traffic_hourly = ev_charging_traffic.drop(columns=columns_to_drop)\n",
        "\n",
        "# Display the first few rows of the updated DataFrame to verify\n",
        "ev_charging_traffic_hourly.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcF57IugPsCx"
      },
      "source": [
        "### Task 6\n",
        "\n",
        "Earlier we saw that the `El_kWh` and `Duration_hours` columns were object data types. Upon further inspection, we see that the reason is that the data is following European notation where commas `,` are used as decimals instead of periods.\n",
        "\n",
        "Replace `,` with `.` in these three columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cExZW0k8PsCx",
        "outputId": "7b1414b1-6e56-455d-b109-936e46a22004"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   User_private El_kWh Duration_hours  month_plugin_Apr  month_plugin_Aug  \\\n",
            "0           1.0    0.3           0.05               0.0               0.0   \n",
            "1           1.0   0.87    0.136666667               0.0               0.0   \n",
            "2           1.0  29.87    8.216388889               0.0               0.0   \n",
            "3           1.0  15.56    24.41972222               0.0               0.0   \n",
            "4           1.0   3.62    0.970555556               0.0               0.0   \n",
            "\n",
            "   month_plugin_Dec  month_plugin_Feb  month_plugin_Jan  month_plugin_Jul  \\\n",
            "0               1.0               0.0               0.0               0.0   \n",
            "1               1.0               0.0               0.0               0.0   \n",
            "2               1.0               0.0               0.0               0.0   \n",
            "3               1.0               0.0               0.0               0.0   \n",
            "4               1.0               0.0               0.0               0.0   \n",
            "\n",
            "   month_plugin_Jun  ...  weekdays_plugin_Saturday  weekdays_plugin_Sunday  \\\n",
            "0               0.0  ...                       0.0                     0.0   \n",
            "1               0.0  ...                       0.0                     0.0   \n",
            "2               0.0  ...                       0.0                     0.0   \n",
            "3               0.0  ...                       1.0                     0.0   \n",
            "4               0.0  ...                       0.0                     0.0   \n",
            "\n",
            "   weekdays_plugin_Thursday  weekdays_plugin_Tuesday  \\\n",
            "0                       0.0                      0.0   \n",
            "1                       0.0                      0.0   \n",
            "2                       0.0                      0.0   \n",
            "3                       0.0                      0.0   \n",
            "4                       0.0                      0.0   \n",
            "\n",
            "   weekdays_plugin_Wednesday  Kroppan_bru_traffic  Moholtlia_traffic  \\\n",
            "0                        0.0               3244.0             1632.0   \n",
            "1                        0.0               3244.0             1632.0   \n",
            "2                        0.0               3605.0             1691.0   \n",
            "3                        0.0               3052.0             1484.0   \n",
            "4                        0.0               1390.0              693.0   \n",
            "\n",
            "   Selsbakk_traffic  Moholt_rampe_2_traffic  \\\n",
            "0             545.0                   194.0   \n",
            "1             545.0                   194.0   \n",
            "2             605.0                   230.0   \n",
            "3             453.0                   224.0   \n",
            "4             226.0                    83.0   \n",
            "\n",
            "   Jonsvannsveien_vest_steinanvegen_traffic  \n",
            "0                                     622.0  \n",
            "1                                     622.0  \n",
            "2                                     771.0  \n",
            "3                                     694.0  \n",
            "4                                     353.0  \n",
            "\n",
            "[5 rows x 27 columns]\n"
          ]
        }
      ],
      "source": [
        "# Replace commas with periods and convert columns to numeric data type\n",
        "columns_to_clean = ['El_kWh', 'Duration_hours']\n",
        "\n",
        "for col in columns_to_clean:\n",
        "    ev_charging_traffic_hourly[col] = ev_charging_traffic_hourly[col].str.replace(',', '.')\n",
        "\n",
        "# Display the updated DataFrame to ensure the columns are cleaned\n",
        "print(ev_charging_traffic_hourly.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fvdMAKnPsCx"
      },
      "source": [
        "### Task 7\n",
        "\n",
        "Next, convert the data types of all the columns of `ev_charging_traffic` to floats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i03vBisPsCx"
      },
      "outputs": [],
      "source": [
        "ev_charging_traffic_hourly = ev_charging_traffic_hourly.astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hz_VnoaPsCx"
      },
      "source": [
        "## Task Group 3 - Train Test Split\n",
        "\n",
        "Next, let's split the dataset into training and testing datasets.\n",
        "\n",
        "The training data will be used to train the model and the testing data will be used to evaluate the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYooKGbpPsCx"
      },
      "source": [
        "### Task 8\n",
        "\n",
        "First, create two datasets from `ev_charging_traffic`:\n",
        "\n",
        "- `X` contains only the input numerical features\n",
        "- `y` contains only the target column `El_kWh`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NSGk9-mPsCx"
      },
      "outputs": [],
      "source": [
        "X = ev_charging_traffic_hourly.drop(columns=['El_kWh'])\n",
        "y = ev_charging_traffic_hourly['El_kWh']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbTbnvH0PsCx"
      },
      "source": [
        "### Task 9\n",
        "\n",
        "Use `sklearn` to split `X` and `y` into training and testing datasets. The training set should use 80% of the data. Set the `random_state` parameter to `2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU9YjWwTPsCx"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "    train_size=0.80,\n",
        "    test_size=0.20,\n",
        "    random_state=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJuFUEyePsCx"
      },
      "source": [
        "## Task Group 4 - Linear Regression Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4PHkRFyPsCx"
      },
      "source": [
        "This section is optional, but useful. The idea is to compare our neural network to a basic linear regression. After all, if a basic linear regression works just as well, there's no need for the neural network!\n",
        "\n",
        "If you haven't done linear regression with scikit-learn before, feel free to use [our solution code](./solutions.html) or to skip ahead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_94M9hMPsCy"
      },
      "source": [
        "### Task 10\n",
        "\n",
        "Use Scikit-learn to train a Linear Regression model using the training data to predict EV charging loads.\n",
        "\n",
        "The linear regression will be used as a baseline to compare against the neural network we will train later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "565GB4HhPsCy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIiZzl5sPsCy"
      },
      "source": [
        "### Task 11\n",
        "\n",
        "Evaluate the linear regression baseline by calculating the MSE on the testing data. Use `mean_squared_error` from `sklearn.metrics`.\n",
        "\n",
        "Save the testing MSE to the variable `test_mse` and print it out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u34_EEl0PsCy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7rfa78LPsCy"
      },
      "source": [
        "Looks like our mean squared error is around `131.4` (if you used different columns in your model than we did, you might have a different value). Remember, this is squared error. If we take the square root, we have about `11.5`. One way of interpreting this is to say that the linear regression, on average, is off by `11.5 kWh`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hproAfq9PsCy"
      },
      "source": [
        "## Task Group 5 - Train a Neural Network Using PyTorch\n",
        "\n",
        "Let's now create a neural network using PyTorch to predict EV charging loads."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE1ZbDQvPsCy"
      },
      "source": [
        "### Task 12\n",
        "\n",
        "First, we'll need to import the PyTorch library and modules.\n",
        "\n",
        "Import the PyTorch library `torch`.\n",
        "\n",
        "From `torch`, import `nn` to access built-in code for constructing networks and defining loss functions.\n",
        "\n",
        "From `torch`, import `optim` to access built-in optimizer algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NddOBCQmPsCy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc_aMBq4PsCy"
      },
      "source": [
        "### Task 13\n",
        "\n",
        "Before training the neural network, convert the training and testing sets into PyTorch tensors and specify `float` as the data type for the values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClqeGfrFPsCy"
      },
      "outputs": [],
      "source": [
        "# Remove NaN values from X_train and adjust y_train accordingly\n",
        "X_train_clean = X_train.dropna()\n",
        "y_train_clean = y_train[X_train_clean.index]\n",
        "X_test_clean = X_test.dropna()\n",
        "y_test_clean = y_test[X_test_clean.index]\n",
        "\n",
        "# Convert to tensors and ensure y_train_tensor is 2D\n",
        "X_train_tensor = torch.tensor(X_train_clean.to_numpy(), dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_clean.to_numpy(), dtype=torch.float32).view(-1, 1)\n",
        "X_test_tensor = torch.tensor(X_test_clean.to_numpy(), dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test_clean.to_numpy(), dtype=torch.float32).view(-1, 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4tEdO_lPsCy"
      },
      "source": [
        "### Task 14\n",
        "\n",
        "Next, let's use `nn.Sequential` to create a neural network.\n",
        "\n",
        "First, set a random seed using `torch.manual_seed(42)`.\n",
        "\n",
        "Then, create a sequential neural network with the following architecture:\n",
        "\n",
        "- input layer with number of nodes equal to the number of training features\n",
        "- a first hidden layer with `56` nodes and a ReLU activation\n",
        "- a second hidden layer with `26` nodes and a ReLU activation\n",
        "- an output layer with `1` node\n",
        "\n",
        "Save the network to the variable `model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGXSZ9ZTPsC1"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(26, 56),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(56, 26),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(26, 1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gadZ2JOBPsC1"
      },
      "source": [
        "### Task 15\n",
        "\n",
        "Next, let's define the loss function and optimizer used for training:\n",
        "\n",
        "- set the MSE loss function to the variable `loss`\n",
        "- set the Adam optimizer to the variable `optimizer` with a learning rate of `0.0007`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOclwh7VPsC1"
      },
      "outputs": [],
      "source": [
        "loss = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.0007)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbMWIT91PsC1"
      },
      "source": [
        "### Task 16\n",
        "\n",
        "Create a training loop to train our neural network for 3000 epochs.\n",
        "\n",
        "Keep track of the training loss by printing out the MSE every 500 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sd0iN6FXPsC2",
        "outputId": "b88593c2-913c-4c26-d222-e20f899d45de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [500/3000], MSE Loss: 121.35372924804688\n",
            "Epoch [1000/3000], MSE Loss: 113.1530990600586\n",
            "Epoch [1500/3000], MSE Loss: 112.26484680175781\n",
            "Epoch [2000/3000], MSE Loss: 106.9486083984375\n",
            "Epoch [2500/3000], MSE Loss: 104.27964782714844\n",
            "Epoch [3000/3000], MSE Loss: 103.15689086914062\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 3000\n",
        "for epoch in range(num_epochs):\n",
        "    predictions = model(X_train_tensor)\n",
        "    MSE = loss(predictions, y_train_tensor)\n",
        "    MSE.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    if (epoch + 1) % 500 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], MSE Loss: {MSE.item()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS6Kr89VPsC2"
      },
      "source": [
        "### Task 17\n",
        "\n",
        "Save the neural network in the `models` directory using the path `models/model.pth`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPERkWetPsC2"
      },
      "outputs": [],
      "source": [
        "torch.save(model, \"models/model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdeP9V9jPsC2"
      },
      "source": [
        "### Task 18\n",
        "\n",
        "Evaluate the neural network on the testing set.\n",
        "\n",
        "Save the testing data loss to the variable `test_loss` and use `.item()` to extract and print out the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KjwPc-CPsC2",
        "outputId": "0d6d13fe-7cbb-4d07-9519-1529e68e4b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test MSE is 106.4807357788086\n",
            "Test Root MSE is 10.318950323497473\n"
          ]
        }
      ],
      "source": [
        "loaded_model = torch.load('models/model.pth')\n",
        "loaded_model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = loaded_model(X_test_tensor)\n",
        "    test_MSE = loss(predictions, y_test_tensor)\n",
        "# show output\n",
        "print('Test MSE is ' + str(test_MSE.item()))\n",
        "print('Test Root MSE is ' + str(test_MSE.item()**(1/2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0iKsdGoPsC2"
      },
      "source": [
        "### Task 19\n",
        "\n",
        "We trained this same model for 4500 epochs locally. That model is saved as `models/model4500.pth`. Load this model using PyTorch and evaluate it. How well does the longer-trained model perform?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7Ezg3FGPsC2",
        "outputId": "03149240-9fbe-47a7-f7a1-baaf8e4b0205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test MSE is 104.2914047241211\n",
            "Test Root MSE is 10.212316325110631\n"
          ]
        }
      ],
      "source": [
        "loaded_model = torch.load('models/model4500.pth')\n",
        "loaded_model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = loaded_model(X_test_tensor)\n",
        "    test_MSE = loss(predictions, y_test_tensor)\n",
        "# show output\n",
        "print('Test MSE is ' + str(test_MSE.item()))\n",
        "print('Test Root MSE is ' + str(test_MSE.item()**(1/2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW7o_RRiPsC2"
      },
      "source": [
        "Pretty cool! The increased training improved our test loss to about `115.2`, a full `12%` improvement on our linear regression baseline. So the nonlinearity introduced by the neural network actually helped us out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NGgFlm4PsC2"
      },
      "source": [
        "That's the end of our project on predicting EV charging loads! Feel free to continue experimenting with this neural network model.\n",
        "\n",
        "Some things you might want to investigate further include:\n",
        "- explore different ways to clean and prepare the data\n",
        "- we added traffic data, but there's no guarantee that more data converts to a better model. Test out different sets of input columns.\n",
        "- test out different number of nodes in the hidden layers, activation functions, and learning rates\n",
        "- train on a larger number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz-bE9ecPsC3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}